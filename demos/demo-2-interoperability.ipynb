{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Demo 2 - Interoperability.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "swift",
      "display_name": "Swift"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1IIvuOcU3nO",
        "colab_type": "text"
      },
      "source": [
        "# Interoperability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLJOEl93eyn7",
        "colab_type": "text"
      },
      "source": [
        "## Import from Python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZRlD4utdPuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import Python"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6DdXZTcesgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let np = Python.import(\"numpy\")\n",
        "let plt = Python.import(\"matplotlib.pyplot\")\n",
        "\n",
        "// Also enable Jupyter's display capabilities\n",
        "%include \"EnableIPythonDisplay.swift\"\n",
        "IPythonDisplay.shell.enable_matplotlib(\"inline\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4FLCl5peuL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let x = np.linspace(0, 10, 100)\n",
        "\n",
        "plt.plot(x, np.sin(x))\n",
        "plt.plot(x, np.cos(x))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY8zcF8YxyEe",
        "colab_type": "text"
      },
      "source": [
        "## Play an AI game from Python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtlPQ2qh_4gZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let gym = Python.import(\"gym\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DWYozGH_8f3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import TensorFlow\n",
        "\n",
        "/// Model parameters and hyperparameters.\n",
        "let hiddenSize = 128\n",
        "let batchSize = 16\n",
        "/// Controls the amount of good/long episodes to retain for training.\n",
        "let percentile = 70\n",
        "\n",
        "/// An episode is a list of steps, where each step records the observation from\n",
        "/// env and the action taken. They will serve respectively as the input and\n",
        "/// target (label) of the neural net training.\n",
        "struct Episode {\n",
        "    struct Step {\n",
        "        let observation: Tensor<Float>\n",
        "        let action: Int32\n",
        "    }\n",
        "\n",
        "    let steps: [Step]\n",
        "    let reward: Float\n",
        "}\n",
        "\n",
        "/// Filtering out bad/short episodes before we feed them as neural net training data.\n",
        "func filteringBatch(\n",
        "  episodes: [Episode],\n",
        "  actionCount: Int\n",
        ") -> (input: Tensor<Float>, target: Tensor<Float>, episodeCount: Int, meanReward: Float) {\n",
        "    let rewards = episodes.map { $0.reward }\n",
        "    let rewardBound = Float(np.percentile(rewards, percentile))!\n",
        "    print(\"rewardBound = \\(rewardBound)\")\n",
        "\n",
        "    var input = Tensor<Float>(0.0)\n",
        "    var target = Tensor<Float>(0.0)\n",
        "    var totalReward: Float = 0.0\n",
        "\n",
        "    var retainedEpisodeCount = 0\n",
        "    for episode in episodes {\n",
        "        if episode.reward < rewardBound {\n",
        "            continue\n",
        "        }\n",
        "\n",
        "        let observationTensor = Tensor<Float>(episode.steps.map { $0.observation })\n",
        "        let actionTensor = Tensor<Int32>(episode.steps.map { $0.action })\n",
        "        let oneHotLabels = Tensor<Float>(oneHotAtIndices: actionTensor, depth: actionCount)\n",
        "\n",
        "        if retainedEpisodeCount == 0 {\n",
        "            input = observationTensor\n",
        "            target = oneHotLabels\n",
        "        } else {\n",
        "            input = input.concatenated(with: observationTensor)\n",
        "            target = target.concatenated(with: oneHotLabels)\n",
        "        }\n",
        "\n",
        "        totalReward += episode.reward\n",
        "        retainedEpisodeCount += 1\n",
        "    }\n",
        "\n",
        "    return (input, target, retainedEpisodeCount, totalReward / Float(retainedEpisodeCount))\n",
        "}\n",
        "\n",
        "struct CartPoleEnvironment {\n",
        "    let env: PythonObject\n",
        "    func reset() -> Tensor<Float> {\n",
        "        return Tensor<Float>(Tensor<Double>(numpy: env.reset())!)\n",
        "    }\n",
        "    func step(_ action: Int32) -> (Tensor<Float>, Float, Bool) {\n",
        "        let (nextObservation, reward, isDone, _) = env.step(Int(action)).tuple4\n",
        "        return (\n",
        "            Tensor<Float>(Tensor<Double>(numpy: nextObservation)!),\n",
        "            Float(reward)!, Bool(isDone)!)\n",
        "    }\n",
        "}\n",
        "\n",
        "extension Tensor where Scalar: TensorFlowFloatingPoint {\n",
        "    func categorical(samples: Int) -> Tensor<Int32> {\n",
        "        let logits = self.rank == 1 ? self.reshaped(to: [1, self.shape[0]]) : self\n",
        "        return Raw.multinomial(\n",
        "            logits: logits,\n",
        "            numSamples: Tensor<Int32>(Int32(samples)))\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnT7vamXWFnN",
        "colab_type": "text"
      },
      "source": [
        "### Neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2gbhNcEWJ4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/// A simple two layer dense neural net.\n",
        "struct Net: Layer {\n",
        "    typealias Input = Tensor<Float>\n",
        "    typealias Output = Tensor<Float>\n",
        "\n",
        "    var l1, l2: Dense<Float>\n",
        "\n",
        "    init(observationSize: Int, hiddenSize: Int, actionCount: Int) {\n",
        "        l1 = Dense<Float>(inputSize: observationSize, outputSize: hiddenSize, activation: relu)\n",
        "        l2 = Dense<Float>(inputSize: hiddenSize, outputSize: actionCount)\n",
        "    }\n",
        "\n",
        "    @differentiable\n",
        "    func call(_ input: Input) -> Output {\n",
        "        return input.sequenced(through: l1, l2)\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddpadylwWKoL",
        "colab_type": "text"
      },
      "source": [
        "### *Observe* and *act*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNj_oYbBWv4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "func nextBatch(env: CartPoleEnvironment, net: Net, batchSize: Int, actionCount: Int) -> [Episode] {\n",
        "    var observation = env.reset()\n",
        "\n",
        "    var episodes: [Episode] = []\n",
        "\n",
        "    // Build up a batch of observations and actions.\n",
        "    for _ in 0..<batchSize {\n",
        "        var steps: [Episode.Step] = []\n",
        "        var episodeReward: Float = 0.0\n",
        "\n",
        "        // This loop runs one episode.\n",
        "        while true {\n",
        "            let action = net(observation.reshaped(to: [1, 4])).categorical(samples: 1).scalarized()\n",
        "            let (nextObservation, reward, isDone) = env.step(action)\n",
        "            steps.append(Episode.Step(observation: observation, action: action))\n",
        "\n",
        "            episodeReward += reward\n",
        "\n",
        "            if isDone == true {\n",
        "                episodes.append(Episode(steps: steps, reward: episodeReward))\n",
        "                observation = env.reset()\n",
        "                break\n",
        "            } else {\n",
        "                observation = nextObservation\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return episodes\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBrWcVm9Yn2w",
        "colab_type": "text"
      },
      "source": [
        "### Load environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVdddhwUYpnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let env = CartPoleEnvironment(env: gym.make(\"CartPole-v0\"))\n",
        "let observationSize = Int(env.env.observation_space.shape[0])!\n",
        "let actionCount = Int(env.env.action_space.n)!\n",
        "var meanRewards: [Float] = []\n",
        "\n",
        "var net = Net(observationSize: Int(observationSize), hiddenSize: hiddenSize, actionCount: actionCount)\n",
        "let optimizer = Adam(for: net, learningRate: 0.01)\n",
        "var batchIndex = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNyB7mv3WvYz",
        "colab_type": "text"
      },
      "source": [
        "###  Loop to learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUpqlZTLx0LX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "while true {\n",
        "    print(\"Processing mini batch \\(batchIndex)\")\n",
        "    batchIndex += 1\n",
        "\n",
        "    let episodes = nextBatch(env: env, net: net, batchSize: batchSize, actionCount: actionCount)\n",
        "    let (input, target, episodeCount, meanReward) = filteringBatch(\n",
        "      episodes: episodes, actionCount: actionCount)\n",
        "\n",
        "    let gradients = withLearningPhase(.training) {\n",
        "        net.gradient { net -> Tensor<Float> in\n",
        "            let logits = net(input)\n",
        "            let loss = softmaxCrossEntropy(logits: logits, probabilities: target)\n",
        "            print(\"loss is \\(loss)\")\n",
        "            return loss\n",
        "        }\n",
        "    }\n",
        "    optimizer.update(&net.allDifferentiableVariables, along: gradients)\n",
        "\n",
        "    print(\"It has episode count \\(episodeCount) and mean reward \\(meanReward)\")\n",
        "    meanRewards.append(meanReward)\n",
        "\n",
        "    if meanReward > 199 {\n",
        "        print(\"Solved\")\n",
        "        break\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "np3szYjSY0II",
        "colab_type": "text"
      },
      "source": [
        "### Plot rewards"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOGyoyxlYyyW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(meanRewards)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EB9huPDde4n6",
        "colab_type": "text"
      },
      "source": [
        "## C Interoperability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQDTY64he5DO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import Glibc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRPjLQvAe-Eb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let address = malloc(32)!\n",
        "let string = address.bindMemory(to: CChar.self, capacity: 32)\n",
        "\n",
        "strcpy(string, \"Plain old C at Google I/O 2019!\")\n",
        "puts(string)\n",
        "\n",
        "free(address)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}