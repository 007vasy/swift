{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Demo 1 - Swift in Colab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "swift",
      "display_name": "Swift"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxBp_tVjT6fB",
        "colab_type": "text"
      },
      "source": [
        "## Hello, Colab!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZRlD4utdPuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let pi = 3.14\n",
        "let y = [1, 2, 3]\n",
        "print(\"Hello Google I/O!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ4SL4_SUA3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let someNumbers = [\n",
        "        \"Prime\": [2, 3, 5, 7, 11, 13],\n",
        "    \"Fibonacci\": [1, 1, 2, 3, 5, 8],\n",
        "       \"Square\": [1, 4, 9, 16, 25],\n",
        "]\n",
        "\n",
        "for (kind, numbers) in someNumbers {\n",
        "    var largest = 0\n",
        "    for x in numbers where x > largest && x.isEven {\n",
        "        largest = x\n",
        "    }\n",
        "    print(\"The largest even \\(kind) is \\(largest)\")\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZSM3m9mUT2F",
        "colab_type": "text"
      },
      "source": [
        "## The Tensor Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAXKpVXRUVSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import TensorFlow\n",
        "\n",
        "let x: Tensor<Float> = [[[1, 2], [4, 5]]]\n",
        "\n",
        "print(\"x + x =\\n\\(x + x)\\n\")\n",
        "print(\"sum = \\(x.sum())\")\n",
        "print(\"stdev = \\(x.standardDeviation(squeezingAxes: 0, 1))\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv8CE8X5Z9Rn",
        "colab_type": "text"
      },
      "source": [
        "## Deep Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXWTF_8zUY_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "struct Model: Layer {\n",
        "    var conv = Conv2D<Float>(filterShape: (5, 5, 3, 6))\n",
        "    var maxpool = MaxPool2D<Float>(poolSize: (2, 2), strides: (2, 2))\n",
        "    var flatten = Flatten<Float>()\n",
        "    var dense = Dense<Float>(inputSize: 36 * 6, outputSize: 10)\n",
        "\n",
        "    @differentiable\n",
        "    func call(_ input: Tensor<Float>) -> Tensor<Float> {\n",
        "        return dense(flatten(maxpool(conv(input))))\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tbiNzRa5uYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// Use random training data.\n",
        "let x = Tensor<Float>(randomNormal: [10, 16, 16, 3])\n",
        "let y = Tensor<Int32>(rangeFrom: 0, to: 10, stride: 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOI-yWFb5v9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var model = Model()\n",
        "let optimizer = SGD(for: model)\n",
        "Context.local.learningPhase = .training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MB4tX4gP5xXr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in 1...10 {\n",
        "    let (loss, grads) = valueWithGradient(at: model) { model -> Tensor<Float> in\n",
        "        let logits = model(x)\n",
        "        return softmaxCrossEntropy(logits: logits, labels: y)\n",
        "    }\n",
        "    print(\"Step \\(i), loss is: \\(loss)\")\n",
        "    optimizer.update(&model.allDifferentiableVariables, along: grads)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}